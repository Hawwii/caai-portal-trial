{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import helpers.cleaning as data_cleaning_utils\n",
    "import scipy.stats as stats\n",
    "import helpers.utils as utils\n",
    "from helpers.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Some participants were not born in the same country as they currently reside in. ['p-6685e2c5fbd787de3b24a2c2', 'p-66967edf8ce4a54036f34ef8', 'p-668126eea930dfc63e6d7d27', 'p-66190827a12b7445ccc6fc87', 'p-664b329dd41d2f1c1cbac1ad', 'p-664a8fa9dcc9b3525dd0627a', 'p-6672e323325f446e7d0989b1', 'p-63103bd06b5135122e25d6c6', 'p-667d73c6c567edc939cbfe30', 'p-66718d62dbfa3d0df3d19c65', 'p-669ff9394403872002cad24a', 'p-66a3abd870ee7ff1a47e2cdf']\n",
      "Removing users who were not born in the same country as they currently reside\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "users_df = data_cleaning_utils.load_qualtrics_csv('data/qualtrics.csv')\n",
    "users_df = data_cleaning_utils.clean_users_df(users_df, keep_only_prolific_for_india=True, keep_only_prolific_for_us=True, remove_born_outside=True, remove_pilot=True)\n",
    "users_df['group'] = None\n",
    "print(len(users_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_df, tasks_df, suggestions_df = utils.construct_dfs_for_analysis(users_df, EVENTS_DIR, TREATMENT_LABEL, CONTROL_LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short Shwartz Value Survey analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssvs_cols = users_df.columns[users_df.columns.str.startswith('ssvs')].tolist()\n",
    "df_ssvs = users_df[~users_df['ssvs_achievement'].isna()][['country'] + ssvs_cols]\n",
    "df_ssvs = utils.compute_ssvs_scores(df_ssvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>shapiro_IND</th>\n",
       "      <th>shapiro_US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ssvs_power</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ssvs_achievement</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ssvs_hedonism</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ssvs_stimulation</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssvs_self-direction</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ssvs_universalism</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ssvs_benevolence</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ssvs_tradition</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ssvs_conformity</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ssvs_security</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Not normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>conservation</td>\n",
       "      <td>Not normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>transcendence</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    col shapiro_IND  shapiro_US\n",
       "0            ssvs_power  Not normal  Not normal\n",
       "1      ssvs_achievement  Not normal  Not normal\n",
       "2         ssvs_hedonism  Not normal  Not normal\n",
       "3      ssvs_stimulation  Not normal  Not normal\n",
       "4   ssvs_self-direction  Not normal  Not normal\n",
       "5     ssvs_universalism  Not normal  Not normal\n",
       "6      ssvs_benevolence  Not normal  Not normal\n",
       "7        ssvs_tradition  Not normal  Not normal\n",
       "8       ssvs_conformity  Not normal  Not normal\n",
       "9         ssvs_security  Not normal  Not normal\n",
       "10         conservation  Not normal      Normal\n",
       "11        transcendence      Normal      Normal"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform Shapiro-Wilk test for normality\n",
    "utils.perform_normality_test(df_ssvs, ssvs_cols + ['conservation', 'transcendence'], filter_col='country', filter_vals=['IND', 'US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f4246\">\n",
       "  <caption>Comparing IND vs US</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f4246_level0_col0\" class=\"col_heading level0 col0\" >col</th>\n",
       "      <th id=\"T_f4246_level0_col1\" class=\"col_heading level0 col1\" >u_stat</th>\n",
       "      <th id=\"T_f4246_level0_col2\" class=\"col_heading level0 col2\" >p_value</th>\n",
       "      <th id=\"T_f4246_level0_col3\" class=\"col_heading level0 col3\" >significant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f4246_row0_col0\" class=\"data row0 col0\" >ssvs_power</td>\n",
       "      <td id=\"T_f4246_row0_col1\" class=\"data row0 col1\" >2399.000000</td>\n",
       "      <td id=\"T_f4246_row0_col2\" class=\"data row0 col2\" >0.000319</td>\n",
       "      <td id=\"T_f4246_row0_col3\" class=\"data row0 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f4246_row1_col0\" class=\"data row1 col0\" >ssvs_achievement</td>\n",
       "      <td id=\"T_f4246_row1_col1\" class=\"data row1 col1\" >2216.000000</td>\n",
       "      <td id=\"T_f4246_row1_col2\" class=\"data row1 col2\" >0.008788</td>\n",
       "      <td id=\"T_f4246_row1_col3\" class=\"data row1 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f4246_row2_col0\" class=\"data row2 col0\" >ssvs_hedonism</td>\n",
       "      <td id=\"T_f4246_row2_col1\" class=\"data row2 col1\" >2157.500000</td>\n",
       "      <td id=\"T_f4246_row2_col2\" class=\"data row2 col2\" >0.022291</td>\n",
       "      <td id=\"T_f4246_row2_col3\" class=\"data row2 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f4246_row3_col0\" class=\"data row3 col0\" >ssvs_stimulation</td>\n",
       "      <td id=\"T_f4246_row3_col1\" class=\"data row3 col1\" >2205.000000</td>\n",
       "      <td id=\"T_f4246_row3_col2\" class=\"data row3 col2\" >0.010984</td>\n",
       "      <td id=\"T_f4246_row3_col3\" class=\"data row3 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f4246_row4_col0\" class=\"data row4 col0\" >ssvs_self-direction</td>\n",
       "      <td id=\"T_f4246_row4_col1\" class=\"data row4 col1\" >1879.000000</td>\n",
       "      <td id=\"T_f4246_row4_col2\" class=\"data row4 col2\" >0.422224</td>\n",
       "      <td id=\"T_f4246_row4_col3\" class=\"data row4 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f4246_row5_col0\" class=\"data row5 col0\" >ssvs_universalism</td>\n",
       "      <td id=\"T_f4246_row5_col1\" class=\"data row5 col1\" >2267.500000</td>\n",
       "      <td id=\"T_f4246_row5_col2\" class=\"data row5 col2\" >0.003075</td>\n",
       "      <td id=\"T_f4246_row5_col3\" class=\"data row5 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f4246_row6_col0\" class=\"data row6 col0\" >ssvs_benevolence</td>\n",
       "      <td id=\"T_f4246_row6_col1\" class=\"data row6 col1\" >2045.000000</td>\n",
       "      <td id=\"T_f4246_row6_col2\" class=\"data row6 col2\" >0.081727</td>\n",
       "      <td id=\"T_f4246_row6_col3\" class=\"data row6 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f4246_row7_col0\" class=\"data row7 col0\" >ssvs_tradition</td>\n",
       "      <td id=\"T_f4246_row7_col1\" class=\"data row7 col1\" >2347.500000</td>\n",
       "      <td id=\"T_f4246_row7_col2\" class=\"data row7 col2\" >0.000880</td>\n",
       "      <td id=\"T_f4246_row7_col3\" class=\"data row7 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f4246_row8_col0\" class=\"data row8 col0\" >ssvs_conformity</td>\n",
       "      <td id=\"T_f4246_row8_col1\" class=\"data row8 col1\" >2529.500000</td>\n",
       "      <td id=\"T_f4246_row8_col2\" class=\"data row8 col2\" >0.000014</td>\n",
       "      <td id=\"T_f4246_row8_col3\" class=\"data row8 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f4246_row9_col0\" class=\"data row9 col0\" >ssvs_security</td>\n",
       "      <td id=\"T_f4246_row9_col1\" class=\"data row9 col1\" >2665.000000</td>\n",
       "      <td id=\"T_f4246_row9_col2\" class=\"data row9 col2\" >0.000000</td>\n",
       "      <td id=\"T_f4246_row9_col3\" class=\"data row9 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f4246_row10_col0\" class=\"data row10 col0\" >conservation</td>\n",
       "      <td id=\"T_f4246_row10_col1\" class=\"data row10 col1\" >2252.000000</td>\n",
       "      <td id=\"T_f4246_row10_col2\" class=\"data row10 col2\" >0.005895</td>\n",
       "      <td id=\"T_f4246_row10_col3\" class=\"data row10 col3\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f4246_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f4246_row11_col0\" class=\"data row11 col0\" >transcendence</td>\n",
       "      <td id=\"T_f4246_row11_col1\" class=\"data row11 col1\" >1488.500000</td>\n",
       "      <td id=\"T_f4246_row11_col2\" class=\"data row11 col2\" >0.176620</td>\n",
       "      <td id=\"T_f4246_row11_col3\" class=\"data row11 col3\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14bb75950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute statistical significance between participants from India and US\n",
    "\n",
    "df_stats = utils.perform_statistical_test(df_ssvs, ssvs_cols + ['conservation', 'transcendence'],\n",
    "                               filter_col='country', filter_vals=['IND', 'US'], test_name='mannwhitney')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country  group\n",
       "IND      AI       36\n",
       "         No AI    24\n",
       "US       AI       29\n",
       "         No AI    29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.groupby(['country', 'group']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: IND\n",
      "Num participants: 60\n",
      "Age: 33.38 ± 11.85\n",
      "Gender {'Male': 0.7166666666666667, 'Female': 0.26666666666666666, 'Prefer not to say': 0.016666666666666666}\n",
      "Education {'Graduation': 0.43333333333333335, 'Post-graduation': 0.4166666666666667, 'Upto grade 12 (Inter)': 0.15}\n",
      "Languages (dedup using ChatGPT) ['Konkani, English and Hindi', 'English, Malayalam, Hindi, Tamil, French', 'Malayalam, English', 'English, Hindi', 'tamil', 'English, Hindi, Gujarati', 'English, Hindi, Punjabi', 'Malayalam, English, Hindi, Tamil', 'English, Hindi, Marathi', 'English, Urdu, Kashmiri', 'Telugu, English, Java, Python', 'English, Kannada, Hindi, Marathi', 'English, Hindi, Malayalam, Tamil ', 'English, Telugu, Hindi ', 'English, Hindi, Punjabi, Gujarati, Urdu and basic German', 'Hindi, English, Marathi', 'English, malayalam, hindi, tamil', 'English, Hindi', 'English', 'English, Hindi', 'English, Hindi, French', 'Hindi, English, German, Sanskrit', 'Marathi English Hindi', 'Hindi, Marathi, English and French', 'English, Hindi, Punjabi', 'English, Telugu, Hindi', 'Hindi English', 'English, Hindi', 'Hindi, English and Bengali', 'Malayalam, English, Hindi', 'Tamil, English', 'English,Hindi', 'English, Tamil', 'English, Marathi, Hindi, Sanskrit', 'Tamil, English, Hindi, Telugu', 'English and hindi', 'english, hindi', 'Hindi, English', 'English, Bengali,Hindi', 'Hindi, Urdu, Marathi, English.', 'English, Hindi, Marathi', 'English, Telugu, Hindi', 'English, Hindi, Punjabi', 'English, Hindi', 'English, Kannada', 'Punjabi, Hindi, English', 'English', 'English, Malayalam, Hindi', 'English, Hindi, Tamil, Gujarathi', 'English', 'English, Hindi, Telugu', 'ENGLISH, HINDI', 'Hindi, English, Urdu', 'Telugu, English, Hindi', 'English, Hindi, Nepali', 'English, Hindi, Punjabi', 'English, Hindi, Punjabi and Bengali.', 'HINDI, ENGLISH, GARHWALI', 'Malayalam, English, Hindi', 'Hindi, English, Malayalam, Gujarati']\n",
      "Occupations (dedup using ChatGPT) ['Counsellor', 'Designer', 'self employed', 'Software Engineer', 'education', 'Freelancer/Consultant', 'Self employed', 'Development Professional', 'Accounting and Finance', 'Student', 'Software Dev', 'Program manager', 'Sales Engineer', 'Software Engigneer', 'Tech entrepreneur, educator and designer', 'Self employed', 'Student', 'Student', 'Student', 'Business', 'IT', 'Student', 'Student', 'finance ', 'Designer', 'Data Analytics', 'Student', 'Teacher', 'Service', 'Student', 'Freelancer', 'Employee', 'Entrepreneur', 'User Experience Designer', 'Assistant Professor', 'Self employed ', 'student', 'Academician', 'Salaried', 'Data Analyst(searching for the job)', 'Freelancer', 'Student', 'Student', 'Sales & Marketing', 'Writer', 'Software Engineer', 'Student', 'Freelancer', 'IT', 'Engineer', 'Academics', 'Intern', 'Doctor', 'Software Engineer', 'Tech Consultant', 'Student', 'Online Tutor', 'Employee in PSU', 'Private company employee', 'Student']\n",
      "\n",
      "Country: US\n",
      "Num participants: 58\n",
      "Age: 36.07 ± 13.52\n",
      "Gender {'Female': 0.5, 'Male': 0.4827586206896552, 'Non-binary / third gender': 0.017241379310344827}\n",
      "Education {'Post-graduation': 0.5, 'Graduation': 0.39655172413793105, 'Upto grade 12 (Inter)': 0.08620689655172414, 'No formal schooling': 0.017241379310344827}\n",
      "Languages (dedup using ChatGPT) ['English', 'English ', 'English', 'English', 'English', 'English', 'English', 'English', 'English, Vietnamese', 'English, some Korean', 'english', 'English', 'English', 'English and Spanish', 'English and French ', 'English', 'english', 'English', 'English', 'English', 'english', 'English, Spanish', 'English, Italian, French', 'english', 'English', 'English', 'English', 'English', 'English', 'English', 'English', 'english, asl', 'English', 'English', 'English', 'English, Japanese', 'English', 'English', 'English', 'English', 'English', 'English', 'English', 'English', 'English', 'English, some German', 'English', 'English and Spanish', 'English, some Spanish', 'English', 'English', 'English, Spanish, Indonesian', 'English and Chinese', 'English', 'English', 'English ', 'English, Spanish', 'English']\n",
      "Occupations (dedup using ChatGPT) ['Cook', 'Homemaker', 'Interventionist', 'Director', 'US ARMY', 'Unemployed', 'Retail worker', 'IT', 'Copywriter', 'full time ph.d. student', nan, 'Unemployed', 'Finance', 'Postdoctoral scholar', 'Food Service Employee', 'unemployed', 'Software development', 'Unemployed', 'teacher', 'Transportation', 'caretaker', 'Software Engineer', 'Graphic Artist', 'manager', 'Veterinary Assistant', 'Certified Oil Lube Technician 3', 'Disabled ', 'health care worker', 'IT Manager', 'Developer', 'Operator', 'home health', 'software developer', 'Unemployed', nan, 'video editor', 'security', 'Driver', 'Marketing/Sales', 'Project Engineer', 'Data Analyst', 'Unemployed and searching', 'Sales', 'IT', 'Real Estate Associate ', 'Student Assistant for a library ', 'construction ', 'Team Leader', 'School Secretary', 'Homemaker', 'Teaching Assistant', 'Business Owner', 'Marketing', 'resarcher', 'Transcriber', 'Consultant ', 'Healthcare', 'Retired, formerly a technical writer']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stats for user demographics table\n",
    "for country in users_df.country.unique():\n",
    "    dft = users_df[users_df.country == country]\n",
    "    print(f'Country: {country}')\n",
    "    print(f'Num participants: {len(dft)}')\n",
    "    age_mean, age_std = dft.age.astype(int).mean(), dft.age.astype(int).std()\n",
    "    print(f'Age: {age_mean:.2f} ± {age_std:.2f}')\n",
    "\n",
    "    genders = dft.gender.value_counts(normalize=True).to_dict()\n",
    "    print(\"Gender\", genders)\n",
    "\n",
    "    education = dft.education.value_counts(normalize=True).to_dict()\n",
    "    print(\"Education\", education)\n",
    "\n",
    "    languages = dft.languages.tolist()\n",
    "    print(\"Languages (dedup using ChatGPT)\", languages)\n",
    "\n",
    "    occupations = dft.occupation.tolist()\n",
    "    print(\"Occupations (dedup using ChatGPT)\", occupations)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 users with no AI use:\n",
      "US    1\n",
      "Name: country, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remove users with no AI use (presumably they didn't engage meaningfully with the study)??\n",
    "ai_reliance_per_user = tasks_df.groupby('user_id')['ai_reliance'].mean()\n",
    "\n",
    "users_with_no_ai_use = ai_reliance_per_user[ai_reliance_per_user == 0].index.tolist()\n",
    "print(f\"{len(users_with_no_ai_use)} users with no AI use:\\n{users_df.loc[users_with_no_ai_use]['country'].value_counts()}\")\n",
    "\n",
    "# users_df = users_df[~users_df.index.isin(users_with_no_ai_use)]\n",
    "# tasks_df = tasks_df[tasks_df['user_id'].isin(users_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caai",
   "language": "python",
   "name": "caai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
