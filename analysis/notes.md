# Learnings from pilot:

1. 20 participants from US, 19 from India. We will have to tone down the numbers we were thinking earlier.
  - One person from batch restricted to India entered their location as US, which is weird.

2. People tried to copy the prompt to find an answer outside, but when they realised they can't they seem to have manually written what they searched.
  - Add to the instructions that you are not allowed to paste content in the textbox.
  - Disable selection of the prompt to make it harder to copy.

3. Indian participants are not engaging meaningfully. Either they accept all suggestions as-is, or they don't accept any and type out what seems like an AI-generated answer. 7-8 responses seem to be from the same user (clearly misuing the system to earn money). It seems useless to do it this way, since users may have a completely different behaviour in real-life.
  - Should I make it very strict – if they leave the portal, the study is invalidated?
  - From the analysis, remove users with zero AI reliance – they have not engaged meaningfully with the system. But how do we weed out bad users from the no-AI case?

TODO:
- Very poor quality: AI generated responses or copied from the web. We might have to make the tasks less generic (e.g., what would you do in this situation...)

# Learnings from study (July 24, 2024)
- Born in a different country (Ghana, Nigeria) but lived in the US for 2-18 years.
  - Remove such cases? Or keep if lived in US for >10 years?
  - Discard

- Some participants didn’t press TAB to use the suggestions but wrote exactly what the suggestion recommended (example: https://drive.google.com/file/d/1J8KdZVygII3xFEuQnUuWu7J5JKlKsuxo/view?usp=sharing). Should I consider this as AI reliance?
  - Yes, only when they write the entire suggestion that was offered
  
- Remove cases with 0% AI reliance and >98% AI reliance? These cases didn’t engage meaningfully with the study.
  - task level or user level?

- SSVS: Statistically significant difference between Indians and Americans on only 3/10 values (benevolence, conformity, security). No stat significant difference even for the computed conservation and self-transcendance scores.

- Suggestion edit rate: what if they change a suggestion in the middle, not the end?